from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
from tensorflow import keras

import sys
import os
import pickle
import music21
import numpy as np
import ast
import matplotlib.pyplot as plt

import tensorflow.keras.layers as ksl
from tensorflow.compat.v1.keras.layers import CuDNNLSTM
import tensorflow.keras.models as ksm
from tensorflow.keras.optimizers import Adam
import tensorflow.keras.utils as ksu

'''Implementation of a GAN to generate classical music
Discriminator Net: LSTM architecture to keep time information.
Generator Net: Perceptron.

I will be training only on part of the MAESTRO dataset, specifically
the works labeled Chopin that are designated to be in the training split.
This is done for time purposes because the processing of files is extremely
slow, and better results might result from keeping data from one composer
instead of a variety.

This is about 60 midi files, each with a variety of length, adding up to be
an unknown amount of time. There is approximately 8MB of processed data.
'''

def parseFiles(dirName):
    '''Read in files of pitches generated by parsemidi.py and stores them
    in one large list for processing in prepare'''
    notes = []
    directory = os.fsencode(dirName) #dirName will be ./data/test/Chopin
    
    for f in os.scandir(dirName): #each file in the directory
        fp = open(f.path, "r")
        c = ast.literal_eval(fp.read())
        notes += c
        fp.close()

    return notes
    

def prepare(notes, seqLen):
    '''prepares the data for use in the neural network by conversion
    to integers and normalized. Takes a fixed sequence length
    from a combination of files'''

    net_in = []
    pnames = sorted(set(n for n in notes)) #get all possible unique pitches
    print(pnames)
    mapping = dict((n, ind) for ind, n in enumerate(pnames)) # create mapping
    print(mapping)
    for i in range(len(notes)-seqLen): # perform mapping
        net_in.append([mapping[c] for c in notes[i:i+seqLen]]) #use the map() function somehow?
    print(net_in)
    net_in = np.reshape(net_in, (len(net_in), seqLen, 1)) #shape into 3-d array

    net_in = (net_in - float(len(pnames))/2) /(float(len(pnames))/2) #normalize to [-1,1]


    return net_in
    pass

class GAN():
    def __init__(self, seqLen):
        self.seqLen = seqLen
        self.shape = (self.seqLen, 1)
        self.latentDim = 1024
        self.dLoss = [] # list of discriminator loss
        self.gLoss = [] # list of generator loss

        opt = Adam(0.0002, 0.5)
        self.discrim = self.discriminator()
        self.discrim.compile(loss='binary_crossentropy', optimizer = opt, metrics=['accuracy'])

        self.generate = self.generator()

        i = ksl.Input(shape=(self.latentDim,))
        generatedSeq = self.generate(i)

        self.discrim.trainable = False
        v = self.discrim(generatedSeq)
        self.combination = ksm.Model(i, v)
        self.combination.compile(loss='binary_crossentropy', optimizer = opt)
        self.combination.summary()
        
    def discriminator(self):
        
        model = ksm.Sequential()
        model.add(CuDNNLSTM(512, input_shape=self.shape, return_sequences=True)) #LSTM architecture
        model.add(ksl.Bidirectional(CuDNNLSTM(512)))
        model.add(ksl.Dense(512)) # densely connectly layer
        model.add(ksl.LeakyReLU(alpha = 0.3))
        model.add(ksl.Dense(256))
        model.add(ksl.LeakyReLU(alpha = 0.3))
        model.add(ksl.Dense(1, activation='sigmoid'))
        model.summary()

        s = ksl.Input(shape=self.shape)
        v = model(s)
        return ksm.Model(s,v)
                  

    def generator(self):
        model = ksm.Sequential()
        model.add(ksl.Dense(256, input_dim=self.latentDim))
        model.add(ksl.LeakyReLU(alpha = 0.3))
        model.add(ksl.BatchNormalization(momentum=0.8))
        
        model.add(ksl.Dense(512))
        model.add(ksl.LeakyReLU(alpha = 0.3))
        model.add(ksl.BatchNormalization(momentum=0.8))
        
        model.add(ksl.Dense(1024))
        model.add(ksl.LeakyReLU(alpha = 0.3))
        model.add(ksl.BatchNormalization(momentum=0.8))

        model.add(ksl.Dense(np.prod(self.shape), activation = 'tanh'))
        model.add(ksl.Reshape(self.shape))
        model.summary()

        n = ksl.Input(shape=self.latentDim)
        s = model(n)
        return ksm.Model(n, s)
        

    def train(self, epochs, batch, sample, notes):
        '''Trains the GAN
        epochs: number of epochs to train for
        batch: size of the batches to train on
        sample: generate some music every # of samples
        '''
        trainingData = prepare(notes, self.seqLen)
        print("Number of training Sequences:", trainingData.shape[0])

        
        fake = np.zeros((batch,1))

    
        for epoch in range(epochs):
            for i in range(0, trainingData.shape[0], batch):
                rSequences = trainingData[i:i+batch]
                real = np.ones((len(rSequences),1))

                noise = np.random.normal(0,1, (batch, self.latentDim))

                fSequences = self.generate.predict(noise)
                loss_r = self.discrim.train_on_batch(rSequences, real)
                loss_f = self.discrim.train_on_batch(fSequences, fake)
                disc_loss = 0.5 * np.add(loss_r, loss_f) #average loss

                noise = np.random.normal(0,1,(batch, self.latentDim))
                gen = np.ones((batch,1))
                gen_loss = self.combination.train_on_batch(noise, gen)
                
                self.dLoss.append(disc_loss[0])
                self.gLoss.append(gen_loss)

            print("Epoch:", epoch, "done")
            self.create(notes, "epoch"+str(epoch))
            self.plotLoss('Epoch' + str(epoch))
                   
            
        pass

    def create(self, inNotes, filename):
        pnames = sorted(set(n for n in inNotes))
        mapping = dict((ind, n) for ind, n in enumerate(pnames))
 
        noise = np.random.normal(0,1, (1, self.latentDim)) #draw from 0 to 1
        p = self.generate.predict(noise) # output ranges from -1 to 1
        print(p)
        pnotes = [(x*((len(mapping)-1)/2))+((len(mapping)-1)/2) for x in p[0]] # normalize to 0 to 683
        pnotes = [mapping[int(x)] for x in pnotes]

        print(pnotes)

        offset = 0
        output = []

        for i in pnotes:
            pattern = i[0]

            if '.' in pattern or pattern.isdigit():
                chordNotes = pattern.split('.')
                notes = []
                for n in chordNotes:
                    print("chord")
                    new = music21.note.Note(int(n))
                    new.storedInstrument = music21.instrument.Piano()
                    notes.append(new)
                ch = music21.chord.Chord(notes)
                ch.offset = offset
                output.append(ch)
            else:
                new = music21.note.Note(pattern)
                new.offset = offset
                new.storedInstrument = music21.instrument.Piano()
                output.append(new)

            offset += 0.5

        midi_stream = music21.stream.Stream(output)
        midi_stream.write('midi', fp=filename+'.mid')

    def plotLoss(self, filename):
        plt.plot(self.dLoss)
        plt.plot(self.gLoss)
        plt.title("Loss per batch")
        plt.legend(['Discriminator', 'Generator'])
        plt.xlabel('Batch')
        plt.ylabel('Loss')

        plt.savefig(filename)

if __name__ == '__main__':
    gan = None

    gan = GAN(200)
    notes = parseFiles("./data/train/Chopin")
    gan.create(notes, 'initial')
    gan.train(epochs=50, batch=32, sample = 1, notes=notes)
    
    gan.create(notes, '50epochs')
    gan.create(notes, '50epochsv2')
    
    ksm.save_model(gan.discrim, "discriminator.h5", save_format = 'h5')
    ksm.save_model(gan.generate, "generate.h5", save_format = 'h5')
    ksm.save_model(gan.combination, "combination.h5", save_format = 'h5')
    
    gan.plotLoss('Final')
    



